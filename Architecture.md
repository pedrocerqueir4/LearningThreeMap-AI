# High-Level Architecture
## Logical Components

### Frontend (SPA)

Pages:
- Conversation list / home
- Conversation view (chat + graph)

UI “zones” (in conversation view):
- Left: list of conversations
- Center: chat interface (messages list, input) and visualization of nodes (React Flow, representing the same conversation)

### Backend (Worker + Hono)

Routes grouped by responsibility:
- /api/conversations – create, list, get details
- /api/messages – create new message (and trigger AI call)
- /api/graph – get graph for a conversation (nodes + edges)

Integrations:
- D1 binding for persistence
- AI HTTP API

### Database (D1)

Basic relational schema:
- conversations
- messages
- nodes
- edges

# Data Model
## Tables

1. conversations

- id (string/UUID)
- title (string)
- created_at (timestamp)
- updated_at (timestamp)

2. messages

- id
- conversation_id
- author (enum/string: 'user' | 'ai')
- content (text)
- created_at (timestamp)

3. nodes

- id
- conversation_id
- message_id (nullable for non-message nodes, but MVP: always link to a message)
- type (string: 'message')
- label (short text for display, e.g. truncated content)
- created_at

4. edges

- id
- conversation_id
- source_node_id 
- target_node_id (can have multiple)
- label (optional, e.g. “follow-up”)
- created_at


## API Design 

Base URL
Backend Worker: /api/...

### 1. Conversations

1. Create conversation
- POST /api/conversations
- Body: { "title": string } (auto-generated by backend if empty)
- Response: { "id": string, "title": string, "created_at": string }

2. List conversations
- GET /api/conversations
- Response: [{ "id": string, "title": string, "created_at": string }]

3. Get conversation details
- GET /api/conversations/:id
- Response: { "id", "title", "created_at", "updated_at" }

### 2. Messages & AI

1. Send user message & get AI reply
- POST /api/messages
- Body:
  {
    "conversationId": "string",
    "content": "user message text"
  }

2. Backend steps:
- Insert user message into messages.
- Create node for user message and edge from previous node (if exists).
- Build context (recent messages) for AI call.
- Call AI API, get response.
- Insert AI message into messages.
- Create node for AI message and an edge user_message_node → ai_message_node.
- Response:
  {
    "userMessage": { ... },
    "aiMessage": { ... },
    "graphDelta": {
      "newNodes": [...],
      "newEdges": [...]
  }
}

### 3. Graph

1. Get full graph for a conversation
- GET /api/graph/:conversationId
- Response:
  {
    "nodes": [...],
    "edges": [...]
}

Nodes include ids, labels, type, author, etc.
Edges include ids, source, target.

## Frontend Architecture
### 1. Screens & Layout

Screen 1 – Conversation list

- Show all conversations from /api/conversations.
- “New conversation” button.
- On click, navigate to conversation view.

Screen 2 – Conversation view

- Layout:
  - Left sidebar: conversation list (optional; or use a separate page).
  - Main column: chat and map.
- Chat area / Map area (React Flow)
  - Shows messages inside of each Node.
  - While waiting for AI response, show loading indicator.
  - Nodes represent conversations, question made by user and answer made by AI.
  - At bottom, a textarea/input for new message, making possible have diferent maps in the same conversation.
  - Edges are directional, simple straight/curved lines.
  - Controls: zoom, pan, fit-to-view.

### 2. State Management with Zustand

Define logical state slices:
1. Conversation slice
    - currentConversationId
    - conversations list
    - Actions: setCurrentConversation, setConversations, addConversation.
2. Messages slice
    - messagesByConversationId
    - Actions: setMessagesForConversation, appendMessages.
3. Map slice
    - graphByConversationId (nodes + edges)
    - Actions: setGraph, applyGraphDelta.
4. UI slice
    - Loading flags: isSendingMessage, isLoadingGraph, etc.
    - Error message strings.

### 3. Backend Architecture (Worker + Hono)

### 1. Request Flow (Send message)

1. Hono route /api/messages receives request.
2. Validate payload (conversationId, content).
3. Use D1 binding:
    - Insert user message into messages.
    - Fetch last node for that conversation to connect edge.
    - Insert node + edge.
4. Build AI API request:
    - Fetch recent N messages for context from messages.
    - Map them into the specific provider format (e.g. OpenAI messages array).
    - fetch AI endpoint with API key from environment variable.
5. On success:
    - Insert AI message into messages.
    - Insert AI node + edge.
    - Return both messages and new nodes/edges.
6. On failure:
    - Return an error response; user message is still stored.

### 2. DB Access Layer (simple, MVP)

Define helper functions (no ORM needed yet):
1. getConversationById(id)
2. createConversation(title)
3. getMessages(conversationId, limit?)
4. createMessage(conversationId, author, content)
5. createNode(...)
6. createEdge(...)
7. getGraph(conversationId)

### 3. Security & Configuration (MVP)

AI API key only available via Worker environment binding (e.g. OPENAI_API_KEY).
Frontend never sees this key.
CORS:
- During development: allow localhost.
- In production: allow only your Cloudflare Pages domain.

Basic rate limiting is optional for MVP, but at least:
- Limit message length client-side.
- Add simple backend check for max length.

### 4. Development & Deployment Workflow

### 1. Local Development

Use npm.
Monorepo:
- frontend/ (Vite + React + TS)
- backend/ (Worker + Hono)

Use:
- ESLint + Prettier for consistent formatting.
- Git + GitHub for version control.

### 2. Deployment Plan

Frontend:
- Build static assets with Vite.
- Deploy on Cloudflare Pages.

Backend:
- Deploy Worker with Wrangler to Cloudflare.
- Bind D1 database to Worker.

Set environment variables for AI API keys in Cloudflare dashboard or wrangler config.
